{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d25c195",
   "metadata": {},
   "source": [
    "# Compile & Run Enformer on Inf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b99e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# patch required to make the neuronx compilation work\n",
    "!pygmentize neuron.patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a9a427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.isdir('enformer-pytorch'):\n",
    "    !git clone -b 0.7.6 https://github.com/lucidrains/enformer-pytorch && \\\n",
    "    cd enformer-pytorch && git apply ../neuron.patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ead8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "if not os.path.isfile(\"test-sample.pt\"):\n",
    "    urllib.request.urlretrieve(\n",
    "        \"https://raw.githubusercontent.com/lucidrains/enformer-pytorch/main/data/test-sample.pt\",\n",
    "        \"test-sample.pt\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab38ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"enformer-pytorch\")\n",
    "import torch\n",
    "from enformer_pytorch import Enformer\n",
    "\n",
    "model = Enformer.from_pretrained('EleutherAI/enformer-official-rough', return_dict=False)\n",
    "model.eval()\n",
    "\n",
    "data = torch.load('test-sample.pt', map_location=torch.device('cpu'))\n",
    "seq, target = data['sequence'].unsqueeze(0), data['target'].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8745dcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from enformer_pytorch.data import str_to_one_hot\n",
    "\n",
    "# this is the expected seq len of the model\n",
    "SEQUENCE_LENGTH=196608\n",
    "\n",
    "def _get_random_input():\n",
    "    seq = \"\".join(\n",
    "        [random.choice(\"ACGT\") for _ in range(SEQUENCE_LENGTH)])\n",
    "    return torch.from_numpy(np.expand_dims(str_to_one_hot(seq), 0).astype(np.float32)),seq\n",
    "inputs,_ = _get_random_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab62441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove dictionaries\n",
    "import types\n",
    "if not hasattr(model, 'forward_'): model.forward_ = model.forward\n",
    "model.forward = types.MethodType(lambda self,x: tuple(self.forward_(x).values()), model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f9eb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# warm up model\n",
    "out = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e2ea14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compile and save\n",
    "%%time\n",
    "import torch_neuronx\n",
    "with torch.no_grad():  \n",
    "    #model_support = torch_neuronx.analyze(model, inputs)\n",
    "    neuron_model = torch_neuronx.trace(\n",
    "         model, inputs,\n",
    "#         compiler_args=[\n",
    "#             \"--auto-cast\", \"none\"\n",
    "#             \"--verbose\", \"debug\",\n",
    "#         ]\n",
    "     )\n",
    "    neuron_model.save(\"neuron_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15678d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_model = torch.jit.load(\"neuron_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2766ced4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a padded input with the test values\n",
    "inputs2 = torch.zeros(inputs.shape)\n",
    "inputs2[:, :seq.shape[1], :] = seq[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaa4d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out1 = model(inputs2)\n",
    "    out2 = neuron_model(inputs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b37b4fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation - class 1 human - CPU: tensor([-0.0305]), Neuron: tensor([-0.0325])\n"
     ]
    }
   ],
   "source": [
    "from enformer_pytorch.modeling_enformer import pearson_corr_coef\n",
    "\n",
    "print(f\"Correlation - class 1 human - CPU: {pearson_corr_coef(out1[0],target)}, Neuron: {pearson_corr_coef(out2[0],target)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b89544b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.7890]),\n",
       " tensor([[[0.0739, 0.0826, 0.0836,  ..., 0.0043, 0.0348, 0.0100],\n",
       "          [0.0748, 0.0844, 0.0911,  ..., 0.0027, 0.0364, 0.0099],\n",
       "          [0.0862, 0.1005, 0.1166,  ..., 0.0030, 0.0402, 0.0096],\n",
       "          ...,\n",
       "          [0.0038, 0.0037, 0.0028,  ..., 0.0037, 0.0488, 0.0098],\n",
       "          [0.0038, 0.0036, 0.0028,  ..., 0.0037, 0.0489, 0.0097],\n",
       "          [0.0038, 0.0036, 0.0028,  ..., 0.0037, 0.0488, 0.0097]]]),\n",
       " tensor([[[-2.2772, -2.2545, -2.1328,  ..., -4.8374, -2.7688, -4.2377],\n",
       "          [-2.3011, -2.2586, -2.0646,  ..., -5.3634, -2.8254, -4.2367],\n",
       "          [-2.0613, -2.0571, -1.7767,  ..., -5.3323, -2.7203, -4.3290],\n",
       "          ...,\n",
       "          [-5.1802, -5.1457, -5.1899,  ..., -5.9974, -3.4966, -5.3061],\n",
       "          [-5.1802, -5.1457, -5.1899,  ..., -5.9974, -3.4966, -5.3061],\n",
       "          [-5.1802, -5.1457, -5.1899,  ..., -5.9974, -3.4966, -5.3061]]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearson_corr_coef(out1[0],out2[0]), out1[0],out2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eafe8c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed CPU: 5049.9802350997925\n",
      "Elapsed Inf2: 583.141565322876\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "it=10\n",
    "with torch.no_grad():\n",
    "    t=time.time()\n",
    "    for i in range(it):\n",
    "        out1 = model(inputs2)\n",
    "    print(f\"Elapsed CPU: {(time.time()-t) * 1000 / it}\")\n",
    "    t=time.time()\n",
    "    for i in range(it):\n",
    "        out2 = neuron_model(inputs2)\n",
    "    print(f\"Elapsed Inf2: {(time.time()-t) * 1000 / it}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
